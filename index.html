<html>
<head>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r71/three.min.js"></script>
	<style>
		/* We want our scene to span the entire window */
		body { margin: 0; }
	</style>
</head>
<body>

	<video id="video" loop webkit-playsinline style="display:none">
		<source src="test.mov">
	</video>

	<script id="fragShader" type="shader-code">
		uniform vec2 res;//The width and height of our screen
		uniform sampler2D bufferTexture;//Our input texture
		uniform vec3 smokeSource;//The x,y are the posiiton. The z is the power/density
		uniform sampler2D videoTexture;
		uniform float time;
		void main() {
			vec2 st = gl_FragCoord.xy / res;
			vec2 uv = st;
			uv *= 0.998;

			vec4 sum = texture2D(bufferTexture, uv);
			vec4 src = texture2D(videoTexture, uv);
			sum.rgb = mix(sum.rbg, src.rgb, 0.01);
			gl_FragColor = sum;
		 	
		 }
	</script>
	<script>
		//@author Omar Shehata. 2015.
		//We are loading the Three.js library from the cdn here: http://cdnjs.com/libraries/three.js/
		var scene;
		var camera;
		var renderer;

		function sceneSetup(){
			//This is the basic scene setup
			scene = new THREE.Scene();
			var width = window.innerWidth;
			var height = window.innerHeight;
			//Note that we're using an orthographic camera here rather than a prespective
			camera = new THREE.OrthographicCamera( width / - 2, width / 2, height / 2, height / - 2, 1, 1000 );
			camera.position.z = 2;

			renderer = new THREE.WebGLRenderer();
			renderer.setSize( window.innerWidth, window.innerHeight );
			document.body.appendChild( renderer.domElement );
		}

		var bufferScene;
		var textureA;
		var textureB;
		var bufferMaterial;
		var plane;
		var bufferObject;
		var finalMaterial;
		var quad;
        var video;
        var videoTexture;

		function videoTextureSetup() {
			video = document.getElementById( 'video' );
			videoTexture = new THREE.VideoTexture( video );

			videoTexture.minFilter = THREE.LinearFilter;
			videoTexture.magFilter = THREE.LinearFilter;
			videoTexture.format = THREE.RGBFormat;
		}

		function bufferTextureSetup(){
			

			//Create buffer scene
			bufferScene = new THREE.Scene();
			//Create 2 buffer textures
			textureA = new THREE.WebGLRenderTarget( window.innerWidth, window.innerHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter});
			textureB = new THREE.WebGLRenderTarget( window.innerWidth, window.innerHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter} );
			//Pass textureA to shader
			bufferMaterial = new THREE.ShaderMaterial( {
				uniforms: {
				 bufferTexture: { type: "t", value: textureA },
				 res : {type: 'v2',value:new THREE.Vector2(window.innerWidth,window.innerHeight)},//Keeps the resolution
				 videoTexture: {type: "t", value: videoTexture },
				 time: {type:"f",value:Math.random()*Math.PI*2+Math.PI}
				},
				fragmentShader: document.getElementById( 'fragShader' ).innerHTML
			} );
			plane = new THREE.PlaneBufferGeometry( window.innerWidth, window.innerHeight );
			bufferObject = new THREE.Mesh( plane, bufferMaterial );
			bufferScene.add(bufferObject);

			//Draw textureB to screen 
			finalMaterial =  new THREE.MeshBasicMaterial({map: textureB});
			quad = new THREE.Mesh( plane, finalMaterial );
			scene.add(quad);
		}

		//Initialize the Threejs scene
		sceneSetup();

		//Setup the frame buffer/texture we're going to be rendering to instead of the screen
		videoTextureSetup();

		bufferTextureSetup();

		

		//Render everything!
		function render() {

		  requestAnimationFrame( render );

		  //Draw to textureB
		  renderer.render(bufferScene,camera,textureB,true);
			
		  //Swap textureA and B
		  var t = textureA;
		  textureA = textureB;
		  textureB = t;
		  quad.material.map = textureB;
		  bufferMaterial.uniforms.bufferTexture.value = textureA;

		  //Update time
		  bufferMaterial.uniforms.time.value += 0.01;

		  //Finally, draw to the screen
		  renderer.render( scene, camera );
		}
		render();


	</script>
</body>
</html>
